{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TODO: Multiclass & Adam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antsh3k/NN-learning/blob/master/3_TODO_Multiclass_%26_Adam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdjVtLYL6sXJ",
        "colab_type": "text"
      },
      "source": [
        "#Sentiment Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_QSfQu7arNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SWITCH TO GPU\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import torch \n",
        "\n",
        "SEED = 15\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X42qEQjcP5Cj",
        "colab_type": "text"
      },
      "source": [
        "# Find index of the maximum value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p32GCDIPOx3f",
        "colab_type": "code",
        "outputId": "68ce3c7e-22ae-4587-95b5-a7e2274b3e11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x = torch.tensor([[0.5, 0.7], [0.3, 0.1]])\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5000, 0.7000],\n",
            "        [0.3000, 0.1000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEhWWk7yOyNN",
        "colab_type": "code",
        "outputId": "b2bb0b4d-d0e0-4674-e72b-6d9235e050ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TODO: Use torch to calculate the maximum value in each row\n",
        "max_row_val = torch.max(x, dim = 1)\n",
        "print(max_row_val[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s4lXNDq6njd",
        "colab_type": "text"
      },
      "source": [
        "# Get the data from github "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0g6YMvNcFUA",
        "colab_type": "code",
        "outputId": "e4eca14c-f48c-4ef7-8534-d833eb521f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/w-is-h/tmp/master/dataset.csv\", encoding='cp1252')\n",
        "x = df['SentimentText'].values[0:6000]\n",
        "y = df['Sentiment'].values[0:6000]\n",
        "print(y)\n",
        "print(x[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 ... 1 1 0]\n",
            "first think another Disney movie, might good, it's kids movie. watch it, can't help enjoy it. ages love movie. first saw movie 10 8 years later still love it! Danny Glover superb could play part better. Christopher Lloyd hilarious perfect part. Tony Danza believable Mel Clark. can't help, enjoy movie! give 10/10!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I9rNmcu6fpZ",
        "colab_type": "code",
        "outputId": "ff5155cc-2e3e-41e7-bccd-8e8add0b8f02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Remove mails and https links\n",
        "pat_1 = r\"(?:\\@|https?\\://)\\S+\"\n",
        "# Remove tags\n",
        "pat_2 = r'#\\w+ ?'\n",
        "# Combine into one regex\n",
        "combined_pat = r'|'.join((pat_1, pat_2))\n",
        "# Remove websites\n",
        "www_pat = r'www.[^ ]+'\n",
        "# Remove HTML tags\n",
        "html_tag = r'<[^>]+>'\n",
        "def data_cleaner(text):\n",
        "  cleantags = \"\"\n",
        "  try:\n",
        "    stripped = re.sub(combined_pat, '', text)\n",
        "    stripped = re.sub(www_pat, '', stripped)\n",
        "    cleantags = re.sub(html_tag, '', stripped)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    cleantags = \"None\"\n",
        "  return cleantags\n",
        "\n",
        "x_original = x\n",
        "x = [data_cleaner(review) for review in x]\n",
        "print(x[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first think another Disney movie, might good, it's kids movie. watch it, can't help enjoy it. ages love movie. first saw movie 10 8 years later still love it! Danny Glover superb could play part better. Christopher Lloyd hilarious perfect part. Tony Danza believable Mel Clark. can't help, enjoy movie! give 10/10!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z75yCgk-7wLa",
        "colab_type": "text"
      },
      "source": [
        "# SpaCy\n",
        "\n",
        "We can use spacy to tokenize the text and further clean it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmE8oH7KbonG",
        "colab_type": "code",
        "outputId": "81610b65-889a-4c23-811e-85d2f90c6493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import spacy\n",
        "from spacy.attrs import LOWER\n",
        "# Load the english model for spacy, the disable part is used to make it faster\n",
        "nlp = spacy.load('en', disable=['ner', 'parser'])\n",
        "\n",
        "tok_snts = []\n",
        "for snt in x:\n",
        "  tkns = [tkn.lemma_.lower() for tkn in nlp.tokenizer(snt) if not tkn.is_punct]\n",
        "  tok_snts.append(tkns)\n",
        "# Save back\n",
        "x = tok_snts\n",
        "# Print the first sentence\n",
        "print(x[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\ufeff1', 'think', 'another', 'disney', 'movie', 'may', 'good', '-pron-', 'have', 'kid', 'movie', 'watch', 'it', 'can', 'not', 'help', 'enjoy', 'it', 'age', 'love', 'movie', '\\ufeff1', 'see', 'movie', '10', '8', 'year', 'late', 'still', 'love', 'it', 'danny', 'glover', 'superb', 'can', 'play', 'part', 'well', 'christopher', 'lloyd', 'hilarious', 'perfect', 'part', 'tony', 'danza', 'believable', 'mel', 'clark', 'can', 'not', 'help', 'enjoy', 'movie', 'give', '10/10']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkRb0cGDJqYh",
        "colab_type": "code",
        "outputId": "7c65132f-116a-4405-aa90-95d50fef7fe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "w2v = Word2Vec(x, size=300, window=6, min_count=4, workers=4)\n",
        "w2v.wv.most_similar(\"bad\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('funny', 0.8728824853897095),\n",
              " ('pretty', 0.8502696752548218),\n",
              " ('plain', 0.829485297203064),\n",
              " ('ok', 0.8288711309432983),\n",
              " ('terrible', 0.8265166282653809),\n",
              " ('stupid', 0.8248448967933655),\n",
              " ('awful', 0.8213958740234375),\n",
              " ('joke', 0.818178653717041),\n",
              " ('dumb', 0.8176071643829346),\n",
              " ('horrible', 0.8149584531784058)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfZsis4V88i-",
        "colab_type": "text"
      },
      "source": [
        "# Convert each sentence into the average sum of the vector representations of its tokens\n",
        "\n",
        "Save the results into a new variable x_emb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTQktTzBdaYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_emb - embedded sentences\n",
        "x_emb = np.zeros((len(x), 300))\n",
        "# Loop over sentences\n",
        "for i_snt, snt in enumerate(x):\n",
        "  cnt = 0\n",
        "  # Loop over the words of a sentence\n",
        "  for i_word, word in enumerate(snt):\n",
        "    if word in w2v.wv:\n",
        "      x_emb[i_snt] += w2v.wv.get_vector(word)\n",
        "      cnt += 1\n",
        "  if cnt > 0:\n",
        "    x_emb[i_snt] = x_emb[i_snt] / cnt\n",
        "# Save the originals, will be needd later\n",
        "x_or = x_emb\n",
        "y_or = y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lATUWE2b9VKd",
        "colab_type": "text"
      },
      "source": [
        "# Split the dataset into train/test - USE SKLEARN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kpy4rEGnghM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_emb, y, test_size=0.2) # TODO: use train_test_split and split x_emb,y so that test=20% and train=80%\n",
        "\n",
        "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo8X-nua4g5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "?train_test_split # if you are ever stuck on a function this is how you ask for help"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZH3ssL6_dK4",
        "colab_type": "text"
      },
      "source": [
        "#Build the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjDb8Wz0m2PU",
        "colab_type": "code",
        "outputId": "61f10a96-7e83-4bf3-e38a-ef08c3c40691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "# Get torch stuff\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import sklearn.metrics\n",
        "\n",
        "device = torch.device('cuda')\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.fc1 = nn.Linear(300, 100)\n",
        "      # TODO Switch from binary to multicalss with 2 classes\n",
        "      self.fc2 = nn.Linear(100, 2) #? nn.Linear(100, 1)\n",
        "      \n",
        "      self.d1 = nn.Dropout(0.5)\n",
        "      \n",
        "    def forward(self, x):\n",
        "      x = self.d1(torch.relu(self.fc1(x)))\n",
        "      x = torch.sigmoid(self.fc2(x))\n",
        "      return x\n",
        "    \n",
        "net = Net()\n",
        "# TODO: Switch from Binary cross entropy to Cross Entropy\n",
        "criterion = nn.CrossEntropyLoss() #? nn.BCELoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.99)\n",
        "\n",
        "# TODO LATER: Switch to Adam\n",
        "# optimizer = optim.Adam(net.parameters)\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-ee32edd407d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# TODO LATER: Switch to Adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad)\u001b[0m\n\u001b[1;32m     40\u001b[0m         defaults = dict(lr=lr, betas=betas, eps=eps,\n\u001b[1;32m     41\u001b[0m                         weight_decay=weight_decay, amsgrad=amsgrad)\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizer got an empty parameter list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'method' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E7VRuEb9bj1",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mXYUTXUoS-t",
        "colab_type": "code",
        "outputId": "da346ae1-88b1-4a0c-db0e-9e47118857b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Move data to the right device\n",
        "x_train = x_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "x_test = x_train.to(device)\n",
        "y_test = y_train.to(device)\n",
        "\n",
        "print(\"IGNORE THE ACC - WE ARE USING A SMALL SUBESET OF THE DATA\")\n",
        "net.train()\n",
        "for epoch in range(5000): \n",
        "  optimizer.zero_grad()\n",
        "  outputs = net(x_train)\n",
        "  loss = criterion(outputs, y_train)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  \n",
        "  # print statistics\n",
        "  if epoch % 500 == 0:\n",
        "      net.eval()\n",
        "      #TODO: the way we calculate the output is wrong, we can't use if x > 0.5, but have to use max index per row\n",
        "      #sklearn.metrics.accuracy_score([1 if x > 0.5 else 0 for x in outputs.cpu().detach().numpy()], y_train.cpu().numpy())\n",
        "      outputs = torch.max(outputs, 1)[1] #? Use max to get the index of max for each row\n",
        "      acc = sklearn.metrics.accuracy_score(outputs.cpu().detach().numpy(), y_train.cpu().numpy())\n",
        "      \n",
        "      outputs_dev = net(x_test)\n",
        "      #TODO: Same for the dev accuracy\n",
        "      outputs_dev = torch.max(outputs_dev, 1)[1]#? Same but for outputs_dev\n",
        "      acc_dev = sklearn.metrics.accuracy_score(outputs_dev.cpu().detach().numpy(), y_test.cpu().numpy()) #?\n",
        "      \n",
        "      print(\"Epoch: {:4} Loss: {:.5f} Acc: {:.3f} Acc Dev: {:.3f}\".format(epoch, loss.item(), acc, acc_dev))\n",
        "      net.train()\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IGNORE THE ACC - WE ARE USING A SMALL SUBESET OF THE DATA\n",
            "Epoch:    0 Loss: 0.69295 Acc: 0.513 Acc Dev: 0.503\n",
            "Epoch:  500 Loss: 0.55449 Acc: 0.745 Acc Dev: 0.753\n",
            "Epoch: 1000 Loss: 0.53744 Acc: 0.765 Acc Dev: 0.770\n",
            "Epoch: 1500 Loss: 0.52923 Acc: 0.776 Acc Dev: 0.789\n",
            "Epoch: 2000 Loss: 0.52551 Acc: 0.780 Acc Dev: 0.796\n",
            "Epoch: 2500 Loss: 0.52123 Acc: 0.785 Acc Dev: 0.797\n",
            "Epoch: 3000 Loss: 0.52477 Acc: 0.785 Acc Dev: 0.795\n",
            "Epoch: 3500 Loss: 0.52565 Acc: 0.778 Acc Dev: 0.796\n",
            "Epoch: 4000 Loss: 0.52553 Acc: 0.784 Acc Dev: 0.795\n",
            "Epoch: 4500 Loss: 0.52536 Acc: 0.777 Acc Dev: 0.792\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B5bFRUwHLcT",
        "colab_type": "code",
        "outputId": "4a071ef4-c1f0-44a2-e3d5-3b16015454a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(outputs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5909e-04, 9.9955e-01],\n",
            "        [9.6494e-01, 3.5134e-02],\n",
            "        [7.0941e-04, 9.9930e-01],\n",
            "        ...,\n",
            "        [1.2137e-01, 8.7822e-01],\n",
            "        [7.7935e-01, 2.2853e-01],\n",
            "        [9.9983e-01, 1.6960e-04]], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
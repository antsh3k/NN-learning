{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TODO: Unbalanced datasets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antsh3k/NN-learning/blob/master/3_TODO_Unbalanced_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdjVtLYL6sXJ",
        "colab_type": "text"
      },
      "source": [
        "#Sentiment Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_QSfQu7arNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SWITCH TO GPU\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import torch \n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "SEED = 15\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s4lXNDq6njd",
        "colab_type": "text"
      },
      "source": [
        "# Get the data from github "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0g6YMvNcFUA",
        "colab_type": "code",
        "outputId": "2e3e0dc6-1125-444b-ca25-01ea156c6fca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/w-is-h/tmp/master/dataset.csv\", encoding='cp1252')\n",
        "x = df['SentimentText'].values\n",
        "y = df['Sentiment'].values\n",
        "print(y)\n",
        "print(x[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 ... 0 0 1]\n",
            "first think another Disney movie, might good, it's kids movie. watch it, can't help enjoy it. ages love movie. first saw movie 10 8 years later still love it! Danny Glover superb could play part better. Christopher Lloyd hilarious perfect part. Tony Danza believable Mel Clark. can't help, enjoy movie! give 10/10!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I9rNmcu6fpZ",
        "colab_type": "code",
        "outputId": "e1edd433-42a1-4ca8-cdeb-0d8af3100d0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Remove mails and https links\n",
        "pat_1 = r\"(?:\\@|https?\\://)\\S+\"\n",
        "# Remove tags\n",
        "pat_2 = r'#\\w+ ?'\n",
        "# Combine into one regex\n",
        "combined_pat = r'|'.join((pat_1, pat_2))\n",
        "# Remove websites\n",
        "www_pat = r'www.[^ ]+'\n",
        "# Remove HTML tags\n",
        "html_tag = r'<[^>]+>'\n",
        "def data_cleaner(text):\n",
        "  cleantags = \"\"\n",
        "  try:\n",
        "    stripped = re.sub(combined_pat, '', text)\n",
        "    stripped = re.sub(www_pat, '', stripped)\n",
        "    cleantags = re.sub(html_tag, '', stripped)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    cleantags = \"None\"\n",
        "  return cleantags\n",
        "\n",
        "x_original = x\n",
        "x = [data_cleaner(review) for review in x]\n",
        "print(x[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first think another Disney movie, might good, it's kids movie. watch it, can't help enjoy it. ages love movie. first saw movie 10 8 years later still love it! Danny Glover superb could play part better. Christopher Lloyd hilarious perfect part. Tony Danza believable Mel Clark. can't help, enjoy movie! give 10/10!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QsHKKGBhVg-Q"
      },
      "source": [
        "# SpaCy\n",
        "\n",
        "We can use spacy to tokenize the text and further clean it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joYR6ueKeWz6",
        "colab_type": "code",
        "outputId": "b5daf8b6-d985-48e8-ab74-51f6f267461e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import spacy\n",
        "from spacy.attrs import LOWER\n",
        "# Load the english model for spacy, the disable part is used to make it faster\n",
        "nlp = spacy.load('en', disable=['ner', 'parser'])\n",
        "\n",
        "tok_snts = []\n",
        "for snt in x:\n",
        "  tkns = [tkn.lemma_.lower() for tkn in nlp.tokenizer(snt) if not tkn.is_punct]\n",
        "  tok_snts.append(tkns)\n",
        "# Save back\n",
        "x = tok_snts\n",
        "# Print the first sentence\n",
        "print(x[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\ufeff1', 'think', 'another', 'disney', 'movie', 'may', 'good', '-pron-', 'have', 'kid', 'movie', 'watch', 'it', 'can', 'not', 'help', 'enjoy', 'it', 'age', 'love', 'movie', '\\ufeff1', 'see', 'movie', '10', '8', 'year', 'late', 'still', 'love', 'it', 'danny', 'glover', 'superb', 'can', 'play', 'part', 'well', 'christopher', 'lloyd', 'hilarious', 'perfect', 'part', 'tony', 'danza', 'believable', 'mel', 'clark', 'can', 'not', 'help', 'enjoy', 'movie', 'give', '10/10']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQc1FRv48n9J",
        "colab_type": "text"
      },
      "source": [
        "# Train word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVSxGpV4cOx8",
        "colab_type": "code",
        "outputId": "f936bb8b-b48f-443b-82c5-0b2a9a90510f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "w2v = Word2Vec(x, size=300, window=6, min_count=4, workers=4)\n",
        "w2v.wv.most_similar(\"bad\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('terrible', 0.7386313080787659),\n",
              " ('awful', 0.7366094589233398),\n",
              " ('horrible', 0.7013458013534546),\n",
              " ('suck', 0.6790038347244263),\n",
              " ('lousy', 0.6755453944206238),\n",
              " ('lame', 0.6420742273330688),\n",
              " ('stupid', 0.6242562532424927),\n",
              " ('damn', 0.6126651167869568),\n",
              " ('alright', 0.6123789548873901),\n",
              " ('crappy', 0.6112472414970398)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfZsis4V88i-",
        "colab_type": "text"
      },
      "source": [
        "# Convert each sentence into the average sum of the vector representations of its tokens\n",
        "\n",
        "Save the results into a new variable x_emb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTQktTzBdaYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_emb - embedded sentences\n",
        "x_emb = np.zeros((len(x), 300))\n",
        "# Loop over sentences\n",
        "for i_snt, snt in enumerate(x):\n",
        "  cnt = 0\n",
        "  # Loop over the words of a sentence\n",
        "  for i_word, word in enumerate(snt):\n",
        "    if word in w2v.wv:\n",
        "      x_emb[i_snt] += w2v.wv.get_vector(word)\n",
        "      cnt += 1\n",
        "  if cnt > 0:\n",
        "    x_emb[i_snt] = x_emb[i_snt] / cnt\n",
        "# Save the originals, will be need later\n",
        "x_or = x_emb\n",
        "y_or = y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lATUWE2b9VKd",
        "colab_type": "text"
      },
      "source": [
        "# Split the dataset into train/test/dev"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoQ8UehuMkmm",
        "colab_type": "code",
        "outputId": "26760b7d-0dcb-459a-f76a-cdb48c3830f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# TODO: Find the indices where y_or == 1 and y_or == 1\n",
        "inds_z = np.where(y_or == 0)[0] # indices where y_or == 0, use numpy or a for loop\n",
        "inds_o = np.where(y_or == 1)[0]# indices where y_or == 1, use numpy or a for loop\n",
        "print(inds_z)\n",
        "print(inds_o)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    1     3     6 ... 24995 24997 24998]\n",
            "[    0     2     4 ... 24993 24996 24999]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_z2V-9-NBft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO\n",
        "x_emb = x_or[np.concatenate((inds_z, inds_o[:1000]))] # Get values from x_or so that we have 12500 negative examples and 1000 positive examples\n",
        "y = y_or[np.concatenate((inds_z, inds_o[:1000]))]# Get values from y_or so that we have 12500 negative examples and 1000 positive examples\n",
        "\n",
        "# TODO:\n",
        "x_one = x_or[inds_o[:1000]] # Create x_one from x_or that has 1000 positive examples \n",
        "x_zero = x_or[inds_z] # Create x_zero from x_or that has 12500 negative examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwu59SGeYKn5",
        "colab_type": "code",
        "outputId": "2001f5c6-bf14-4e9a-944d-4d36d47c52f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(y.shape)\n",
        "print(x_emb.shape)\n",
        "print(\"Number of positive examples in y: \" + str(np.sum(y)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13500,)\n",
            "(13500, 300)\n",
            "Number of positive examples in y: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEi8yXP5L0D5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get torch stuff\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import sklearn.metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kpy4rEGnghM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(SEED)\n",
        "y = y.reshape(-1)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_emb, y, test_size=0.2, random_state=SEED)\n",
        "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "x_one = torch.tensor(x_one, dtype=torch.float32)\n",
        "x_zero = torch.tensor(x_zero, dtype=torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZH3ssL6_dK4",
        "colab_type": "text"
      },
      "source": [
        "#Build the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjDb8Wz0m2PU",
        "colab_type": "code",
        "outputId": "23d21dc8-490f-4e51-b9d8-5dbe957cf4c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "device = torch.device('cuda')\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.fc1 = nn.Linear(300, 100)\n",
        "      self.fc4 = nn.Linear(100, 2)\n",
        "      \n",
        "      self.d1 = nn.Dropout(0.5)\n",
        "      \n",
        "    def forward(self, x):\n",
        "      x = self.d1(torch.relu(self.fc1(x)))\n",
        "      x = torch.sigmoid(self.fc4(x))\n",
        "      return x\n",
        "# Create the network and get CE loss\n",
        "net = Net()\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.1, 0.9]).to(device))\n",
        "# Make a SGD optimizer with lr=0.002 and momentum=0.99\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.02, momentum=0.99)\n",
        "# Move the net to the device\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc1): Linear(in_features=300, out_features=100, bias=True)\n",
              "  (fc4): Linear(in_features=100, out_features=2, bias=True)\n",
              "  (d1): Dropout(p=0.5)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E7VRuEb9bj1",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mXYUTXUoS-t",
        "colab_type": "code",
        "outputId": "8e446a70-96bd-4549-f8f6-a288473bae38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Move data to the right device\n",
        "x_train = x_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "x_test = x_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "net.train()\n",
        "losses = []\n",
        "accs = []\n",
        "accs_dev = []\n",
        "for epoch in range(10000): \n",
        "  optimizer.zero_grad()\n",
        "  outputs = net(x_train)\n",
        "  loss = criterion(outputs, y_train)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 500 == 0:\n",
        "      net.eval()\n",
        "      acc = sklearn.metrics.accuracy_score(torch.max(outputs, 1)[1].cpu().detach().numpy(), y_train.cpu().numpy())\n",
        "      \n",
        "      outputs_dev = net(x_test)\n",
        "      acc_dev = sklearn.metrics.accuracy_score(torch.max(outputs_dev, 1)[1].cpu().detach().numpy(), y_test.cpu().numpy())\n",
        "      accs_dev.append(acc_dev)\n",
        "      \n",
        "      # TODO: calculate the f1_score, precision and recall\n",
        "      outputs_idx = torch.max(outputs_dev, 1)[1].cpu().detach().numpy() # Get the index of max per row\n",
        "      f1_dev = sklearn.metrics.f1_score(outputs_idx, y_test.cpu().numpy()) # Use f1 from sklearn\n",
        "      p_dev = sklearn.metrics.precision_score(outputs_idx, y_test.cpu().numpy()) # Use precision from sklearn\n",
        "      r_dev = sklearn.metrics.recall_score(outputs_idx, y_test.cpu().numpy()) # Use recall from sklearn\n",
        "      \n",
        "      print(\"Epoch: {:4} Loss: {:.5f} Acc: {:.3f} Acc Dev: {:.3f} F1 Dev: {:.3f} p Dev: {:.3f} r Dev: {:.3f}\".format(epoch, loss.item(), acc, acc_dev, f1_dev, p_dev, r_dev))\n",
        "      net.train()\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:    0 Loss: 0.69183 Acc: 0.756 Acc Dev: 0.927 F1 Dev: 0.048 p Dev: 0.028 r Dev: 0.161\n",
            "Epoch:  500 Loss: 0.45306 Acc: 0.868 Acc Dev: 0.861 F1 Dev: 0.420 p Dev: 0.768 r Dev: 0.289\n",
            "Epoch: 1000 Loss: 0.43976 Acc: 0.875 Acc Dev: 0.861 F1 Dev: 0.419 p Dev: 0.763 r Dev: 0.288\n",
            "Epoch: 1500 Loss: 0.43351 Acc: 0.885 Acc Dev: 0.869 F1 Dev: 0.432 p Dev: 0.757 r Dev: 0.302\n",
            "Epoch: 2000 Loss: 0.42803 Acc: 0.890 Acc Dev: 0.871 F1 Dev: 0.430 p Dev: 0.740 r Dev: 0.303\n",
            "Epoch: 2500 Loss: 0.42433 Acc: 0.895 Acc Dev: 0.873 F1 Dev: 0.430 p Dev: 0.734 r Dev: 0.304\n",
            "Epoch: 3000 Loss: 0.42039 Acc: 0.899 Acc Dev: 0.875 F1 Dev: 0.430 p Dev: 0.718 r Dev: 0.307\n",
            "Epoch: 3500 Loss: 0.41588 Acc: 0.902 Acc Dev: 0.875 F1 Dev: 0.430 p Dev: 0.718 r Dev: 0.307\n",
            "Epoch: 4000 Loss: 0.41408 Acc: 0.905 Acc Dev: 0.878 F1 Dev: 0.434 p Dev: 0.712 r Dev: 0.312\n",
            "Epoch: 4500 Loss: 0.40955 Acc: 0.909 Acc Dev: 0.880 F1 Dev: 0.433 p Dev: 0.701 r Dev: 0.313\n",
            "Epoch: 5000 Loss: 0.40813 Acc: 0.911 Acc Dev: 0.883 F1 Dev: 0.438 p Dev: 0.695 r Dev: 0.319\n",
            "Epoch: 5500 Loss: 0.40572 Acc: 0.913 Acc Dev: 0.888 F1 Dev: 0.449 p Dev: 0.695 r Dev: 0.332\n",
            "Epoch: 6000 Loss: 0.40229 Acc: 0.918 Acc Dev: 0.891 F1 Dev: 0.457 p Dev: 0.701 r Dev: 0.339\n",
            "Epoch: 6500 Loss: 0.40107 Acc: 0.919 Acc Dev: 0.893 F1 Dev: 0.456 p Dev: 0.684 r Dev: 0.342\n",
            "Epoch: 7000 Loss: 0.39869 Acc: 0.925 Acc Dev: 0.895 F1 Dev: 0.454 p Dev: 0.667 r Dev: 0.344\n",
            "Epoch: 7500 Loss: 0.39571 Acc: 0.926 Acc Dev: 0.899 F1 Dev: 0.461 p Dev: 0.661 r Dev: 0.353\n",
            "Epoch: 8000 Loss: 0.39514 Acc: 0.928 Acc Dev: 0.899 F1 Dev: 0.462 p Dev: 0.661 r Dev: 0.355\n",
            "Epoch: 8500 Loss: 0.39199 Acc: 0.931 Acc Dev: 0.899 F1 Dev: 0.460 p Dev: 0.655 r Dev: 0.355\n",
            "Epoch: 9000 Loss: 0.39440 Acc: 0.932 Acc Dev: 0.902 F1 Dev: 0.458 p Dev: 0.633 r Dev: 0.359\n",
            "Epoch: 9500 Loss: 0.39079 Acc: 0.932 Acc Dev: 0.903 F1 Dev: 0.467 p Dev: 0.650 r Dev: 0.365\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGec8wtj7FcU",
        "colab_type": "code",
        "outputId": "1b075f25-8e7e-4d4c-f7bc-105cba6d8239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.sum(torch.max(outputs_dev, 1)[1].cpu().detach().numpy()) # the model doesnt know the importance and therefore thinks everything is a 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHCQE6WQp-lR",
        "colab_type": "code",
        "outputId": "97e8fd18-a470-48e0-b7b7-1dac3fbd8fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tmp = torch.tensor([7, 11, 12, 33, 4, 5])\n",
        "# TODO: Randomly select 3 examples from the 'tmp' tensor\n",
        "sample = tmp[torch.randperm(len(tmp))[0:3]] # select a random choice\n",
        "print(sample)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([33,  5,  7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phE_06u-q5I7",
        "colab_type": "code",
        "outputId": "738165e6-9315-4c88-9d31-4360f8350ecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tmp = torch.tensor([7, 11, 12, 33, 4, 5])\n",
        "tmp2 = torch.tensor([23, 111])\n",
        "# TODO: Concat the two tmp tensor into tmp3\n",
        "tmp3 = torch.cat((tmp, tmp2)) #?\n",
        "print(tmp3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  7,  11,  12,  33,   4,   5,  23, 111])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRoJm6arNrvB",
        "colab_type": "code",
        "outputId": "f6547cbd-123b-487b-d519-3e6cf721b615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Create the network and get BCE loss\n",
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#criterion = nn.CrossEntropyLoss(weight=[0.8, 0.2])\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.05, momentum=0.99)\n",
        "net.to(device)\n",
        "\n",
        "# Let's do the same but with BATCHES\n",
        "x_train = x_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "x_test = x_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "x_zero = x_zero.to(device)\n",
        "x_one = x_one.to(device)\n",
        "net.train()\n",
        "losses = []\n",
        "accs = []\n",
        "accs_dev = []\n",
        "\n",
        "batch_size = 1000\n",
        "num_batches = int(np.ceil(len(x_train)/batch_size))# Calculate the number of batches per epoch, given the batch size above, base it on the length of x_train\n",
        "for epoch in range(5000): \n",
        "  for i in range(num_batches):\n",
        "    x_train_batch = torch.cat((x_one[torch.randperm(len(x_one))[0:500]], x_zero[torch.randperm(len(x_zero))[0:500]])) # Randomly select 500 positve and 500 negative examples, use x_one and x_zero\n",
        "    y_train_batch = torch.zeros(1000, dtype=torch.long) # Create the corresponding labels \n",
        "    y_train_batch[0:500] = 1\n",
        "    y_train_batch = y_train_batch.to(device)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(x_train_batch)\n",
        "    loss = criterion(outputs, y_train_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if epoch % 500 == 0:\n",
        "      net.eval()\n",
        "      outputs = net(x_train)\n",
        "      acc = sklearn.metrics.accuracy_score([1 if x > 0.5 else 0 for x in torch.max(outputs, 1)[1].cpu().detach().numpy()], y_train.cpu().numpy())\n",
        "\n",
        "      outputs_dev = net(x_test)\n",
        "      f1_dev = f1_score(y_test.cpu().numpy(), torch.max(outputs_dev, 1)[1].cpu().detach().numpy())\n",
        "      p_dev = precision_score(y_test.cpu().numpy(), torch.max(outputs_dev, 1)[1].cpu().detach().numpy())\n",
        "      r_dev = recall_score(y_test.cpu().numpy(), torch.max(outputs_dev, 1)[1].cpu().detach().numpy())\n",
        "      \n",
        "      print(\"Epoch: {:4} Loss: {:.5f} Acc: {:.3f} Acc Dev: {:.3f} F1 Dev: {:.3f} p Dev: {:.3f} r Dev: {:.3f}\".format(epoch, loss.item(), acc, acc_dev, f1_dev, p_dev, r_dev))\n",
        "      net.train()\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:    0 Loss: 0.69046 Acc: 0.160 Acc Dev: 0.903 F1 Dev: 0.133 p Dev: 0.071 r Dev: 0.989\n",
            "Epoch:  500 Loss: 0.40421 Acc: 0.920 Acc Dev: 0.903 F1 Dev: 0.587 p Dev: 0.432 r Dev: 0.915\n",
            "Epoch: 1000 Loss: 0.39713 Acc: 0.940 Acc Dev: 0.903 F1 Dev: 0.671 p Dev: 0.526 r Dev: 0.927\n",
            "Epoch: 1500 Loss: 0.37480 Acc: 0.953 Acc Dev: 0.903 F1 Dev: 0.722 p Dev: 0.592 r Dev: 0.927\n",
            "Epoch: 2000 Loss: 0.36843 Acc: 0.960 Acc Dev: 0.903 F1 Dev: 0.758 p Dev: 0.641 r Dev: 0.927\n",
            "Epoch: 2500 Loss: 0.37429 Acc: 0.965 Acc Dev: 0.903 F1 Dev: 0.788 p Dev: 0.686 r Dev: 0.927\n",
            "Epoch: 3000 Loss: 0.36586 Acc: 0.971 Acc Dev: 0.903 F1 Dev: 0.820 p Dev: 0.735 r Dev: 0.927\n",
            "Epoch: 3500 Loss: 0.37114 Acc: 0.972 Acc Dev: 0.903 F1 Dev: 0.816 p Dev: 0.729 r Dev: 0.927\n",
            "Epoch: 4000 Loss: 0.36633 Acc: 0.976 Acc Dev: 0.903 F1 Dev: 0.828 p Dev: 0.749 r Dev: 0.927\n",
            "Epoch: 4500 Loss: 0.36650 Acc: 0.977 Acc Dev: 0.903 F1 Dev: 0.839 p Dev: 0.766 r Dev: 0.927\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}